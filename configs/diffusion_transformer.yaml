infra: diffusion
model: transformer

diffusion:
  seq_length: 1024
  feature_size: 24
  label_dim: 30
  timesteps: 100
  sampling_timesteps: 100
  loss_type: 'l2'
  beta_schedule: 'linear'
  use_ff: True
  use_label: False



backbone:
  n_feat: 24
  n_channel: 1024
  n_layer_enc: 4
  n_layer_dec: 4
  d_model: 64
  n_heads: 8
  attn_pdrop: 0.2
  resid_pdrop: 0.2
  mlp_hidden_times: 4
  block_activate: GELU
  max_len: 1024
  kernel_size: 5
  padding: 2 

optimizer:
  lr: 0.00001
  betas: [0.9,0.99]

batch_size: 8