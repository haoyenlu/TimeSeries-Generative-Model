infra: diffusion
model: transformer

diffusion:
  seq_length: 256
  feature_size: 24
  label_dim: 30
  timesteps: 300
  sampling_timesteps: 300
  loss_type: 'l2'
  beta_schedule: 'linear'
  use_ff: False
  use_label: False



backbone:
  n_feat: 24
  n_channel: 256
  n_layer_enc: 4
  n_layer_dec: 4
  d_model: 64
  n_heads: 4
  attn_pdrop: 0.3
  resid_pdrop: 0.3
  mlp_hidden_times: 4
  block_activate: GELU
  max_len: 256
  kernel_size: 5
  padding: 2 

optimizer:
  lr: 0.0003
  betas: [0.9,0.99]

batch_size: 8